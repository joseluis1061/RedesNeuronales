{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de clientes bancarios\n",
    "\n",
    "Esta es la segunda versión del modelo **RNA** usando **K-folds cross validation**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sesgo y varianza\n",
    "**Sesgo:** El sesgo se define como la diferencia entre el valor real y, y el valor calculado y_hat en el **entrenamiento**. Esta medida esta inversamente relacionada con la complejidad de los modelos. A mayor complejidad del modelo, obtendremos un bajo sesgo. En el caso de redes neuronales aumentar la complejidad esta relasionado con aumentar el número de capas y la cantidad de neuronas dentro de cada capa. Se debe recordar que a medida que aumentamos la complejidad incurriremos en overfitting. Si lo analisas de manera mas consiente tiene logica, pues al sobre entrenar el modelo, las predicciones seran exactamente o casi las mismas medidas reales. Una condición no deseada. \n",
    "\n",
    "![Overfit and underfit](./img/Overfit.bmp)\n",
    "\n",
    "**Varianza:** Por otro lado la varianza se trata de la variabilidad que obtenemos en los resultados del modelo al entregarle datos no vistos o mejor conocidos como datos de **test**. Es natural que las medidas obtenidas no sean exactamente iguales con datos no vistos por el modelo, pero se espera que el modelo sea capaz de encontrar patrones que le ayuden a interpretar estos nuevos datos, entregando resulatados diferencias minimas entre el resultado real y el predicho, osea con baja varianza. Nuevamente se puede inferir que a medida que un modelo presenta un overfit o sobre entrenamiento, obtengamos datos con una varianz alta. Esto se debe a que el modelo ha memorizado los datos de entrenamiento y no sabe como responder a datos no vistos. \n",
    "\n",
    "\n",
    "**Conclusión 1:** Podemos ver entoces que si disminuimos la varianza del modelo, terminaremos tambien por minimizar el sesgo. Nuestro objetivo entonces es diminuir la varianza de nuestros modelos. \n",
    "\n",
    "![Overfit and underfit](./img/VarianzaYSesgo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. k-fold cross validation\n",
    "Es un metodo que nos ayuda a disminuir la varianza de nuesto sistema sin incurrir en overfiting. El metodo consiste en:\n",
    "\n",
    "1. Dividir los datos en folds o grupos, se recomienda usar entre 5-10 divisiones. \n",
    "2. En cada iteracion tomaremos un grupo de datos para usarlo como test. \n",
    "3. En cada iteración se cambia el grupo de test de tal modo que el anterior grupo que se uso para test pasara a ser de entrenamiento.\n",
    "4. De esta manera, al terminar de recorrer todas las iteraciones habremos usado todos los datos para test y para entrenamiento.\n",
    "5. Al final el algoritmo nos entregara la presición media entre todos los k-folds que implementamos. Es natural que se haga así, pues si tomamos el mejor resultado, tendriamos un sesgo en la información.\n",
    "\n",
    "De esta manera el sesgo o bias y la varianza tienden a disminuir sin caer en overfit. \n",
    "\n",
    "![Overfit and underfit](./img/k-fold.png)\n",
    "\n",
    "Como se ha mensionado en el resumen del metódo, es necesario cambiar la manera en que se dividin los datos de train. Se procedera a cambiar la versión anterior del código para implementar K-folds, esto se hace en el tramo de código que implementa el modelo, todos los procesos anteriores son validos hasta este punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargar los datos\n",
    "data = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = (10000, 10) y= (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Separar variables dependientes e independientes\n",
    "X = data.iloc[:,3:13].values\n",
    "y = data.iloc[:,13].values\n",
    "print(f'X = {X.shape} y= {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decodificar datos categoricos\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Hacemos una variable dummy para la columna 1 de paises\n",
    "ct = ColumnTransformer([(\"Geography\", OneHotEncoder(), [1])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "# Y una variable binaria o de nivel para la columna 2 genero de los clientes\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 4] = labelencoder_X.fit_transform(X[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n"
     ]
    }
   ],
   "source": [
    "#Eliminar una columna de variables dummy para evitar la multicolinealidad\n",
    "X = X[:,1:]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (8000, 11), X_test(2000, 11), y_train(8000,), y_test(2000,)\n"
     ]
    }
   ],
   "source": [
    "#Dividir datos en train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print(f'X_train {X_train.shape}, X_test{X_test.shape}, y_train{y_train.shape}, y_test{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar los datos de train\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Creamos un objeto base para escalar las variables\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "#Usamos la misma base de escala para los datos de test pues pertenecen al mismo grupo\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias\n",
    "1. Se debe notar que usaremos wrappers o fragmentos de código de scikit_learn pero implementados en keras, osea es una combinación de las dos librerias. \n",
    "2. cross_val_score implementa K-folds y sera el encargado de ejecutar el entrenamiento de los datos. \n",
    "3. Es necesario definir nuestro modelo como una función a la cual llamaremos para implementar el nuevo metódo de train y test.\n",
    "4. El encargado de hacer este proceso es el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construir la red neuronal artificial RNA\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "#Función para construir nuestro modelo\n",
    "def model_clasificator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 6, kernel_initializer = \"uniform\", activation = \"relu\", input_dim = 11))\n",
    "    model.add(Dense(units=6, kernel_initializer = 'uniform', activation='relu'))\n",
    "    #Agregar la capa de salida\n",
    "    model.add(Dense(units=1, kernel_initializer = 'uniform', activation='sigmoid'))\n",
    "    #Mostrar un resumen del modelo \n",
    "    model.summary()\n",
    "    #Compilar el modelo\n",
    "    model.compile(optimizer = \"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***KerasClassifier*** requiere como argumentos:\n",
    "- build_fn = función con nuestro modelo compilado\n",
    "- Parametros de sklearn: Como se indico es un wrapper, el cual contiene la libreria de sklearn, por lo tanto, usaremos los parametros del .fit de esta libreria, epochs, batch_size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invocaremos el modelo mediante una variable clasifier\n",
    "clasifier = KerasClassifier(build_fn = model_clasificator, epochs = 100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***cross_val_score*** este proceso retorna varias medidas de los resultados de nuestro modelo, en este caso [accuracy] de cada iteración, por lo tanto es necesario guardar esto datos en un array. Los argumentos para esta función son:\n",
    "1. estimator = objeto que usaremos para medir las presiciones obtenidos en este caso el clasifier\n",
    "2. X = Conjunto de datos original que usaremos para entrenamiento del cual sacaremos un porcentaje para validar en cada iteración. \n",
    "3. y = Conjunto de datos con etiquetas de train\n",
    "4. cv = número de folds para hacer la cross validation se recomienda 5 - 10. Se pueden superar este valor de 10 si tienes una maquina potente. \n",
    "5. n_jobs = Si deseas usar todos los core de tu máquina para resolver el ajuste de modelos pues escribir -1 en este parametro.\n",
    "6. verbose = 1 para motrar los resultados de cada ajuste 0 para ocultarlos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  1.7min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "accurasies = cross_val_score(estimator = clasifier, X = X_train, y = y_train, cv = 10, n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84500003, 0.83249998, 0.87      , 0.84875   , 0.85000002,\n",
       "       0.82625002, 0.84750003, 0.83125001, 0.81124997, 0.84875   ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluar las presiciones obtenidas con el metodo de validación cruzada\n",
    "accurasies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediremos cual es la media de la presición obtenida y la varainza, de esta manera podemos determinar si son altas o bajas y podremos situarnos en alguna de las cuatro posibilidades vistas en el apartado inicial del código. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianza = 0.015395319632211923 presición media = 0.8411250054836273\n"
     ]
    }
   ],
   "source": [
    "media = accurasies.mean()\n",
    "varianza = accurasies.std()\n",
    "print(f'Varianza = {varianza} presición media = {media}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis:** Tenemos una varianza baja pero una presición un poco alejada del centro, por lo tanto podemos concluir que tenemos poca varianza y alto sesgo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2c2eaee8aff5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Testear el modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Testear el modelo\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_hat = (y_hat>0.5)\n",
    "print(y_hat[1:5,:])\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "print((cm[0][0]+cm[1][1])/cm.sum())\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
